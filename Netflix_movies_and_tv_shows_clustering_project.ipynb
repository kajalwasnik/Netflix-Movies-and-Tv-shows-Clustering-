{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kajalwasnik/kajalwasnik/blob/main/Netflix_movies_and_tv_shows_clustering_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Netflix-Movies and Tv-shows-Clustering**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "\n",
        "**Name** - Kajal Purushottam Wasnik"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix is an online platform that offers subscription-based streaming services for entertainment, encompassing a diverse selection of content, mainly categorized into movies and television shows. Over the years, it has emerged as the most popular Over-The-Top (OTT) platform globally, accessible to individuals worldwide. Despite the option for customers to terminate their memberships at any time, maintaining user interest is crucial for the company. This underscores the importance of recommendation systems, which play a key role in providing relevant suggestions to users.\n",
        "\n",
        "As a media distribution corporation, Netflix originated with DVD delivery by mail and has since evolved significantly, focusing primarily on video streaming. The content available on the platform includes licensed material as well as original productions.\n",
        "\n",
        "While Netflix initially emphasized movies, television series have become a more prominent genre in recent times. Operating on a subscription model, Netflix grants customers unlimited access to its content for a fee.\n",
        "\n",
        "This project involves working with Netflix data to discern recent trends and gain insights into the presented material, sourced from Flixable, a third-party Netflix search engine. Notably, an analysis by Flixable in 2018 revealed a significant increase in the number of TV series on Netflix since 2010, while the number of movies decreased. This prompted the need for a recommendation system, which we developed by evaluating the data and clustering similar content based on text-based attributes.\n",
        "\n",
        "Key steps in the project include:\n",
        "\n",
        "1. Exploring the dataset by examining its head and tail.\n",
        "\n",
        "2. Describing the dataset by calculating mean, minimum, maximum, and data types of columns.\n",
        "\n",
        "3. Extracting information about non-null counts in column values.\n",
        "\n",
        "4. Counting distinct values in each column.\n",
        "\n",
        "5. Determining the shape of the dataset (number of rows and columns).\n",
        "\n",
        "6. Addressing null values in certain columns by filling them with mode or replacing them with 'No Cast.'\n",
        "\n",
        "7. Plotting relevant graphs to extract information.\n",
        "\n",
        "8. Implementing Natural Language Processing (NLP) techniques, such as tokenization, punctuation removal, stopword removal, and word stemming.\n",
        "\n",
        "9. Employing clustering models like K-means Clustering and Agglomerative Clustering.\n",
        "\n",
        "10. Utilizing techniques like the Elbow method, Silhouette Score, and Dendrogram to determine the number of clusters in K-means.\n",
        "\n",
        "11. Developing a recommendation system using K-means clustering results.\n",
        "\n",
        "The project successfully conducted Exploratory Data Analysis (EDA), revealing critical findings to address significant business challenges. The implemented models, particularly K-means clustering, performed well despite the data's volume and complexity."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset we currently possess contains information about TV shows and movies accessible on Netflix as of 2019. This data was obtained from Flixable, an external Netflix search engine.\n",
        "\n",
        "A compelling report from 2018 provided intriguing statistics about Netflix's content landscape. According to this report, the number of TV shows on Netflix had nearly tripled since 2010, while the count of movies had decreased by over 2,000 titles within the same timeframe. This shift underscores a significant transformation in the platform's content focus, with a notable emphasis on TV shows.\n",
        "\n",
        "Further exploration of this dataset presents an exciting opportunity to uncover additional insights. By incorporating external datasets, such as IMDB ratings and Rotten Tomatoes scores, we can delve deeper into the quality and reception of the content offered by Netflix. This integration opens up avenues for discovering compelling findings and gaining a more comprehensive understanding of the platform's content offerings."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "#Importing important libaries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "\n",
        "# Importing visualization libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "%matplotlib inline\n",
        "import matplotlib.ticker as mtick\n",
        "from matplotlib.pyplot import figure\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline as py\n",
        "import plotly.express as px\n",
        "\n",
        "#importing stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "#for tokenization\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "#import stemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "# Importing Principal Component Analysis (PCA)\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Importing Machin learning Algorithms\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as sch\n",
        "\n",
        "#Here we imported path,Image,WordCloud,STOPWORDS,ImageColorGenerator\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"
      ],
      "metadata": {
        "id": "3qDxrG04uB0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "# first 5 rows of data\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# last 5 rows of data\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "Cdr68pmjvE1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "print(f'Netflix = {df.shape[0]} Rows , {df.shape[1]} columns.')"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "8vnLa_ggvcf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "df.duplicated().sum()\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum().sort_values(ascending = False)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "import missingno as msno"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "msno.matrix(df)"
      ],
      "metadata": {
        "id": "N3PMlBW1vzFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#total null values\n",
        "df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "Cy_jHU68v5Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In there dataset five columns have missing Values director,cast,country,date added and rating.\n",
        "\n",
        "Total null values are 3631"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dataset Columns\n",
        "df.keys()"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   show_id : Unique ID for every Movie / Tv Show\n",
        "*   type : Identifier - A Movie or TV Show\n",
        "\n",
        "\n",
        "\n",
        "*  title : Title of the Movie / Tv Show\n",
        "*   director : Director of the Movie\n",
        "\n",
        "\n",
        "\n",
        "*   cast : Actors involved in the movie / show\n",
        "*   country : Country where the movie / show was produced\n",
        "\n",
        "\n",
        "\n",
        "*   date_added : Date it was added on Netflix\n",
        "*   release_year : Actual Releaseyear of the movie / show\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   rating : TV Rating of the movie / show\n",
        "*   duration : Total Duration - in minutes or number of seasons\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   listed_in : Genere\n",
        "*   description: The Summary description\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Creating a copy of original dataset to keep it safe\n",
        "df_new = df.copy()\n",
        ""
      ],
      "metadata": {
        "id": "gdPGyIxpxiYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "df['type'].value_counts()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix has 5377 movies and 2410 TV shows, there are more number movies on Netflix than TV shows."
      ],
      "metadata": {
        "id": "pSozgKEMxy95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'No cast' will be used to fill in any blank spaces in the 'cast' column.\n",
        "# If any values are missing, the word \"No cast\" will be used in their stead.\n",
        "df['cast'].fillna(value='No cast',inplace=True)"
      ],
      "metadata": {
        "id": "hYlZdUU7x51I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the mode, or most frequent value, to fill in the missing entries in the 'country' column.\n",
        "# If any values are missing, the mode value of the 'country' column will be used as a replacement.\n",
        "df['country'].fillna(value=df['country'].mode()[0],inplace=True)\n",
        ""
      ],
      "metadata": {
        "id": "F7QfHA1Bx8F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the rows with missing values in the 'date_added' and 'rating' columns\n",
        "# If there are any missing values in these columns, the corresponding rows are dropped\n",
        "df.dropna(subset=['date_added','rating'],inplace=True)"
      ],
      "metadata": {
        "id": "r0dzguXWyAHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping Director Column\n",
        "df.drop(['director'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "RVJbAqw_yFDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning the Ratings into grouped categories\n",
        "ratings = {\n",
        "    'TV-PG': 'Older Kids',\n",
        "    'TV-MA': 'Adults',\n",
        "    'TV-Y7-FV': 'Older Kids',\n",
        "    'TV-Y7': 'Older Kids',\n",
        "    'TV-14': 'Teens',\n",
        "    'R': 'Adults',\n",
        "    'TV-Y': 'Kids',\n",
        "    'NR': 'Adults',\n",
        "    'PG-13': 'Teens',\n",
        "    'TV-G': 'Kids',\n",
        "    'PG': 'Older Kids',\n",
        "    'G': 'Kids',\n",
        "    'UR': 'Adults',\n",
        "   'NC-17': 'Adults'\n",
        "}\n",
        "\n",
        "df['All Ages'] = df['rating'].replace(ratings)"
      ],
      "metadata": {
        "id": "xtBrUV1LyKxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type should be a catego\n",
        "df['type'] = pd.Categorical(df['type'])\n",
        "df['All Ages'] = pd.Categorical(df['All Ages'], categories=['Kids', 'Older Kids', 'Teens', 'Adults'])"
      ],
      "metadata": {
        "id": "oK-q4StwyNvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "6Pbr5kOPyYkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# first bar chart\n",
        "# pie chart\n",
        "# Check how many defaulter and non defaulter.\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,6))\n",
        "ax = df['type'].value_counts().plot(kind='bar',title=\"Type\",ax=axes[0])\n",
        "df['type'].value_counts().plot(kind='pie',title=\"type\",autopct='%1.1f%%',ax=axes[1], explode=[0.1,0.1])\n",
        "ax.set_ylabel(\"Count\")\n",
        "ax.set_xlabel(\"'TV Show', 'Movie'\")\n",
        "fig.tight_layout()\n",
        ""
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choose this because a bar chart from the matplotlib package is a helpful method of graphically displaying the distribution of various values inside a variable."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The movie collection is far larger than the TV show collections. 30.9% of TV series and 69.1% of movies."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "Answer Here - Netflix offers a wider variety of movies than TV series, which is good for their company as movies often bring in more money than TV episodes."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "#creating two extra columns\n",
        "tv_shows=df[df['type']=='TV Show']\n",
        "movies=df[df['type']=='Movie']\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv_ratings = tv_shows.groupby(['rating'])['show_id'].count().reset_index(name='count').sort_values(by='count',ascending=False)\n",
        "fig_dims = (20,7)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "sns.pointplot(x='rating',y='count',data=tv_ratings)\n",
        "plt.title('TV Show Ratings',size='20')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vMJRMk1UzDVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Movie Ratings based on All Ages Groups\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.title('movie ratings')\n",
        "sns.countplot(x=movies['rating'],hue=movies['All Ages'],data=movies,order=movies['rating'].value_counts().index)"
      ],
      "metadata": {
        "id": "eqdVxRKJzO7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Matplotlib software was used to build the Bar chart, which is an effective tool for graphically illustrating the distribution of various values inside a variable."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The majority of TV ratings, or adult ratings, are on TV-MA.\n",
        "\n",
        "In both instances, TV-MA has the largest number of ratings for television programs, i.e. adult ratings. The most viewers tune into TV-MA."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "Answer Here - The bulk of Netflix's programming has ratings for viewers Kids and older and adult audiences. This is helpful because the platform primarily targets adult viewers, improving the probability of drawing in and keeping a bigger audience of enthusiastic viewers."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a line chart to visualize the number of movies and TV shows released each year\n",
        "#Extracting the count of movies and TV shows for each year\n",
        "movies_year = movies['release_year'].value_counts().sort_index(ascending=False)\n",
        "tvshows_year = tv_shows['release_year'].value_counts().sort_index(ascending=False)\n",
        "#Creating a line plot using Seaborn\n",
        "sns.set(style='whitegrid', font_scale=1.2)\n",
        "fig, ax = plt.subplots(figsize=(20,7))\n",
        "\n",
        "ax = sns.lineplot(x=movies_year.index, y=movies_year.values, color='red', label='Movies', linewidth=2.5, marker='o')\n",
        "ax = sns.lineplot(x=tvshows_year.index, y=tvshows_year.values, color='blue', label='TV Shows', linewidth=2.5, marker='o')\n",
        "\n",
        "#Customizing the plot\n",
        "plt.xticks(rotation=90)\n",
        "ax.set_xlabel('Release Year', fontsize=15)\n",
        "ax.set_ylabel('Number of Titles', fontsize=15)\n",
        "ax.set_title('Production Growth Yearly', fontsize=19, pad=15)\n",
        "plt.legend(fontsize=15)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b8_CpKKezwdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose this graph because it offers a fascinating look at how films and TV series have been distributed over time. The various lines for movies and TV shows make it simple to compare the two, and the line plot depicts the trend in the annual release of movies and TV shows. This chart also employs color coding to distinguish between movies and TV shows, which makes it easier to read and more aesthetically pleasing. Overall, this graph is a useful tool for examining the connection between the quantity of movies and TV shows released and the year they were first released."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The quantity of motion pictures and television programs that are released each year can give us information on the evolution of the production of media material across time.\n",
        "*   We can observe that between the mid-2000s and 2020, there were much more movies made.\n",
        "\n",
        "\n",
        "*   Although not as much as TV shows, the quantity of TV shows created has also increased.\n",
        "*   Additionally, the graph reveals a decline in movie production in 2020, which could be brought on by the COVID-19 epidemic.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "Gained knowledge can have a good commercial impact by giving investors, streaming services, and content producers useful information. For instance, the rise in movie production may signal a change in consumer preferences toward movies, which may be utilized to inform platform offerings and content creation. The COVID-19 epidemic may have a positive effect on movie creation, but it may also have a negative effect on streaming services and content creators' income."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Chart - 4 visualization code\n",
        "# bar plot for age group of audience\n",
        "plt.figure(figsize=(20,7))\n",
        "df['All Ages'].value_counts().plot(kind='bar')\n",
        ""
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Matplotlib software was used to build the Bar chart, which is an effective tool for graphically illustrating the distribution of various values inside a variable."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead than expressly aiming at children, Netflix largely concentrates on offering material that appeals to the interests and preferences of Adults and Teen audiences."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It may be assumed that the material provided by the site is well-suited to their likes and preferences as a substantial number of Netflix users are adults and teenagers. As a consequence, more individuals will probably find the information captivating and interesting."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "sns.set(rc={'figure.figsize':(20,7)})\n",
        "ax = sns.countplot(data = df, x = 'All Ages', hue = 'type',palette = 'pastel')\n",
        "for p in ax.patches:\n",
        "   ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+0.01))\n",
        ""
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A countplot from the Seaborn library is a particular kind of plot that enables us to quickly contrast and compare two values of a variable."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In comparison to other age groups, Netflix gives much more material to Millennials, with Kids having the least quantity of content available. The database largely comprises of a vast selection of adult-targeted films, while the number of TV programs is about evenly distributed between Adults and Teens."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given that movies make up a larger portion of Netflix's overall content than TV series do, there is more content devoted to the movies area than to the TV shows section."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code#Analysing top10 genre of the movies\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.title('Top10 Genre of Movies',fontweight=\"bold\")\n",
        "sns.countplot(y=movies['listed_in'],data=movies,order=movies['listed_in'].value_counts().index[0:10])"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysing top10 genres of TVSHOWS\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.title('Top10 Genre of TV Shows',fontweight=\"bold\")\n",
        "sns.countplot(y=tv_shows['listed_in'],data=tv_shows,order=tv_shows['listed_in'].value_counts().index[0:10])"
      ],
      "metadata": {
        "id": "Zt9cXvgo1VUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A countplot from the Seaborn library is a particular kind of plot that enables us to quickly contrast and compare two values of a variable."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 The most popular Netflix category is documentaries, which are followed by stand-up comedy, Drams, and foreign films.\n",
        "\n",
        "2 . The most popular Netflix TV program category is kids TV."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because International Movies appeal to the majority of Netflix users, there is an appropriate amount of content in that category.While humor is ideal for unwinding and having fun, documentaries are excellent for learning. People are drawn to them and become enamored with these genres because of this."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "df_duration = df.groupby(['duration'])['show_id'].count().sort_values(ascending= False).reset_index()\n",
        "df_duration\n",
        ""
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (20, 6))\n",
        "sns.barplot(data = df_duration, x = df_duration['duration'][:20], y = df_duration['show_id'])\n",
        "plt.title('Duration of the shows')\n",
        "plt.xticks(rotation = 90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CYSfQqHK1yrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A barplot from the Seaborn library is a particular kind of plot that enables us to quickly contrast and compare two values of a variable."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   When a platform-produced TV program, movie, or web series has at least one season, it can be noticed that the data's biggest quantity of material is Season 1.\n",
        "*  Netflix TV series tend to be arranged into seasons rather than being released one episode at a time or in tiny batches, as seen by the fact that \"Season 1\" is the most frequent time period. It implies that\n",
        "\n",
        "\n",
        "*  It follows that viewers are more inclined to watch new episodes when they initially air rather than waiting for the following season to be published as \"Season 1\" is the most typical duration of TV shows on Netflix. It could suggest what is most likely. This may be because Netflix invests heavily in marketing and promotion of new episodes, or it might be because viewers are more inclined to be interested in shows when they are initially launched.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These observations could aid in directing Netflix's approach for producing and acquiring content. Netflix is well-informed about how it structures and distributes original material, as well as how it allocates resources to develop content that connects with viewers, according to its awareness of viewers' watch-time preferences. You are capable of making wise choices."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Creating the actors plot\n",
        "sns.set(rc={'figure.figsize':(30,8)})\n",
        "ax = sns.countplot(data = df_new, x='cast',palette=\"Spectral\",order=df['cast'].value_counts().index[0:15])\n",
        "plt.title('Actors on Netflix',fontsize = 25  )\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
        ""
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A barplot from the Seaborn library is a particular kind of plot that enables us to quickly contrast and compare two values of a variable."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The narrative makes it clear that the top Netflix content performers are David Attenborough, Samuel West, Jeff Dunham, and Kevin Hart. They often create material that appeals to the audience and gets good ratings."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This information reveals that the performers who have appeared in the most Netflix programming are also the most well-known. Users now have access to a wide variety of high-caliber media that stars these well-known performers."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "sns.set(rc={'figure.figsize':(30,8)})\n",
        "g = sns.countplot(data = df, x='country',palette=\"Paired_r\",order=df['country'].value_counts().index[0:10],hue = 'rating', )\n",
        "sns.move_legend(g, \"upper left\", bbox_to_anchor=(.90, .95), title='Country vs Rating')\n",
        ""
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A barplot from the Seaborn library is a particular kind of plot that enables us to quickly contrast and compare two values of a variable."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The United States creates a lot of material for Netflix since it has a diverse range of cultures. The variety of information that is made available reduces as a country's overall output does."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Netflix offers a lot of content with different ratings, which is great because the United States has a diverse range of cultures."
      ],
      "metadata": {
        "id": "vCt9RLiG3AE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df"
      ],
      "metadata": {
        "id": "MAYxtcmt23vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "# Create a figure and set its size\n",
        "plt.figure(figsize=(20, 7))\n",
        "\n",
        "# Extract the duration values as integers using regex and plot a histogram\n",
        "sns.histplot(movies['duration'].str.extract('(\\d+)').astype(int), kde=True, color='blue',)\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Distribution of Movie Durations', fontweight='bold')\n",
        "\n",
        "# Set the x-axis label\n",
        "plt.xlabel('Duration (minutes)')\n",
        "\n",
        "# Set the y-axis label\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size\n",
        "plt.figure(figsize=(20, 7))\n",
        "# Extract the duration values as integers using regex\n",
        "movies['minute'] = movies['duration'].str.extract('(\\d+)').apply(pd.to_numeric)\n",
        "\n",
        "# Calculate the average movie duration by rating\n",
        "duration_year = movies.groupby(['rating'])['minute'].mean()\n",
        "\n",
        "# Create a DataFrame to store the results and sort by average duration\n",
        "duration_net_df = pd.DataFrame(duration_year).sort_values('minute')\n",
        "\n",
        "# Create a bar plot of the average movie duration by rating\n",
        "ax = sns.barplot(x=duration_net_df.index, y=duration_net_df.minute)\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title(\"Average Movie Duration by Rating\", fontweight='bold')\n",
        "\n",
        "# Set the x-axis label\n",
        "plt.xlabel(\"Rating\")\n",
        "\n",
        "# Set the y-axis label\n",
        "plt.ylabel(\"Average Duration (minutes)\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sV5DYgHI3Rck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A barplot from the Seaborn library is a particular kind of plot that enables us to quickly contrast and compare two values of a variable."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data also showed that NC-17 movies frequently had the longest runtimes, maybe because these films frequently deal with mature issues that need more time to be adequately conveyed. The shortest average runtime is seen in movies with a TV-Y classification, which is appropriate for all youngsters. This implies that films in this category tend to be shorter and have simpler themes and narratives that are suitable for younger audiences. Content producers and distributors that want to comprehend consumer preferences and trends in the film business may find this information useful."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Businesses in the film industry and streaming platforms may benefit from the knowledge gained through audience behavior analysis since it will enable them to better understand their audiences' tastes and provide content that is more relevant to them. For instance, they could decide to concentrate on producing longer, more mature material for adult audiences if they notice that movies with a mature classification typically have longer runtimes.They could refrain from funding comparable initiatives in the future, so reducing the range of content accessible to viewers. Ultimately, before making decisions that might have an influence on their growth, organizations must carefully weigh the possible positive and negative implications of insights."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Word Cloud library\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        ""
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text documents\n",
        "text = \" \".join(word for word in df['title'])\n",
        "\n",
        "# create the word cloud using WordCloud library\n",
        "wordcloud = WordCloud(stopwords=STOPWORDS, background_color='white', min_font_size=15).generate(text)\n",
        "\n",
        "# plot the word cloud\n",
        "plt.imshow(wordcloud,  interpolation='bilinear')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "NrAAT9vq3mHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because of wordcloud library use of alphabet analysis so that whey use this chart"
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The word 'Love', 'Christmas', 'Man', 'World', 'Life', 'Girl', and 'Story' are commonly seen in the movie title column."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "# Set the figure size to 20x7\n",
        "plt.figure(figsize=(20,7))\n",
        "\n",
        "# Create a countplot for the 'country' column\n",
        "# Order the bars in descending order by their value counts\n",
        "# Limit the plot to show only the top 15 countries\n",
        "# Use different colors for 'TV Show' and 'Movie' categories\n",
        "sns.countplot(x=df['country'], order=df['country'].value_counts().index[0:15], hue=df['type'])\n",
        "\n",
        "# Rotate the x-axis tick labels by 50 degrees for better visibility\n",
        "plt.xticks(rotation=50)\n",
        "\n",
        "# Set the plot title with larger font size and bold text\n",
        "plt.title('Top 15 Countries with Most Content', fontsize=15, fontweight='bold')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A barplot from the Seaborn library is a particular kind of plot that enables us to quickly contrast and compare two values of a variable."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The list shows the top 15 nations that contributed to Netflix, with the United States having produced the most material there, followed by India."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our data shows that the United States has the most titles accessible on Netflix, closely followed by India. Notably, of all the nations covered in the research, India has the most films."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "# split the cast and string\n",
        "plt.figure(figsize=(20,6))\n",
        "# split the cast and string\n",
        "cast_movies = df[df.cast != 'unknown'].set_index('title').cast.str.split(', ', expand=True).stack().reset_index(level=1, drop=True)\n",
        "# Create a countplot for the 'Movies cast' column\n",
        "sns.countplot(y=cast_movies, order=cast_movies.value_counts().index[:10], palette='bright')\n",
        "plt.title('Top 10 Actor acted in Movies on Netflix')\n",
        "plt.show();\n",
        ""
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the number of Netflix movies they appeared in, we visualize the top 10 actors in movies."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indian actors make up the most percentage of the top 10 actors in Netflix movies. Anupam Kher and Shah Rukh Khan are the top two actors in terms of the most films they have appeared in."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above graph aids the industry in identifying which of the top 10 actors have roles in Netflix-hosted material. Understanding the popularity of the actors who performed in the majority of Netflix material will aid the business."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chart - 13 popular Director**"
      ],
      "metadata": {
        "id": "2DUWwPak5BOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 14 visualization code\n",
        "# Top directors or popular directors on netflix\n",
        "directors = df_new[df_new.director != 'unknown'].set_index('title').director.str.split(', ', expand=True).stack().reset_index(level=1, drop=True)\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.countplot(y=directors, order=directors.value_counts().index[:10], palette='pastel')\n",
        "plt.title('Top 10 Directors')\n",
        "plt.show();\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "JmxgrbNy5JRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Why did you pick the specific chart?**"
      ],
      "metadata": {
        "id": "oFnZzli95QyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We depict the most renowned or well-known Netflix directors."
      ],
      "metadata": {
        "id": "4QL1xZ395U_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What is/are the insight(s) found from the chart?**"
      ],
      "metadata": {
        "id": "nWOxEr3j5X07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " We can observe that the top 10 Netflix directors with the most material are generally foreign. The most prolific filmmaker on Netflix, Jan Suter has produced a lot of stuff."
      ],
      "metadata": {
        "id": "unklNK9G5cx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Will the gained insights help creating a positive business impact?**"
      ],
      "metadata": {
        "id": "6eCeUs6l5fu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "yKxDUGoG5jO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will aid the industry in understanding the top 10 filmmakers responsible for the Netflix content. Reaching out to well-known filmmakers for future content directions that Netflix will generate will aid with the insight."
      ],
      "metadata": {
        "id": "MDiPmT8H5nuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# preparing data for heatmap\n",
        "# data for correlation\n",
        "df['count'] = 1\n",
        "heatmap = df.groupby('country')[['country', 'count']].sum().sort_values(by='count',ascending=False).reset_index()[:10]\n",
        "heatmap = heatmap[heatmap != 'unknown']\n",
        "heatmap = heatmap['country']\n",
        "\n",
        "corr = df.loc[df['country'].isin(heatmap)]\n",
        "corr = pd.crosstab(corr['country'], corr['All Ages'], normalize = 'index').T\n",
        "corr\n",
        "# Correlation Heatmap visualization code\n",
        "\n",
        "countries =['United States', 'India', 'United Kingdom', 'Canada', 'Japan', 'France', 'South Korea', 'Spain', 'Egypt']\n",
        "rating = ['Adults', 'Teens', 'Older Kids', 'Kids']\n",
        "\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.heatmap(corr.loc[rating, countries], cmap='YlGnBu', linewidth=2.5, fmt='1.0%', annot_kws={'fontsize':12}, annot=True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We display the relationship between the ratings of the streaming material on Netlfix and the various nations."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The United States and the United Kingdom have comparable rating ages, which indicates that people in both nations want to view similar kinds of content."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the dataset columns are all in string format and pair plots need numerical data to provide useful visualizations, we are unable to make a pair plot using the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "ptwj2I596D3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the United States, Netflix has the most programming, followed by India. The most Netflix movies come from India.\n",
        "\n",
        "\n",
        "\n",
        "*   Null hypothesis H0 : The typical amount of movies available on Netflix in the United States is the same as that available in India.\n",
        "*   Alternate hypothesis HA : The average number of Netflix movies in the US is higher than the average number of Netflix movies in India.\n",
        "\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries for hypothesis testing\n",
        "from scipy.stats import uniform\n",
        "from scipy.stats import norm\n",
        "from scipy.stats import chisquare\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import t\n",
        "from scipy.stats import f\n",
        "from scipy.stats import ttest_ind\n",
        "import scipy.stats as stats"
      ],
      "metadata": {
        "id": "rNf4eDfa6irw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Filter the movies DataFrame to create two new DataFrames:\n",
        "# One containing only movies produced in the United States, and one containing only movies produced in India\n",
        "us_movie_df = movies[movies.country == 'United States']\n",
        "india_movie_df = movies[movies.country == 'India']\n",
        "\n",
        "# Perform a two-sample t-test between the release years of the two groups of movies\n",
        "t, p = ttest_ind(us_movie_df['release_year'], india_movie_df['release_year'], equal_var=False)\n",
        "\n",
        "# Set the significance level to 0.05\n",
        "alpha = 0.05\n",
        "\n",
        "# Print the results\n",
        "print('t-statistic:', t)\n",
        "print('p-value:', p)\n",
        "\n",
        "\n",
        "# Check if the calculated p-value is less than the significance level\n",
        "if p < alpha:\n",
        "  # If the p-value is less than the significance level, reject the null hypothesis\n",
        "  print(\"We reject the null hypothesis.\")\n",
        "else:\n",
        "  # If the p-value is greater than or equal to the significance level, fail to reject the null hypothesis\n",
        "  print(\"We fail to reject the null hypothesis.\")\n",
        "\n",
        "# deleting the temporary dataframe we obtained to calculate the alpha value\n",
        "del us_movie_df\n",
        "del india_movie_df"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a two-sample t-test, also known as an independent samples t-test or unpaired t-test, to compare the amount of movies accessible on Netflix in the US and India. I conducted the test using the ttest_ind function from the scipy.stats module, which is appropriate for examining the means of two independent samples. I was able to perform this test, compute the p-value, and establish whether there is a significant difference in the quantity of movies produced in the two nations."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the two-sample t-test is appropriate for comparing the means of two independent samples, I chose it for this investigation. To find out if there is a noticeable variation in the average number of movies between the United States and India, we have two independent sets of Netflix movie data for each nation."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis Testing to check is there is any relation between year_added and type:\n",
        "\n",
        "\n",
        "\n",
        "*   **Null Hypothesis H0:** The type of material that is contributed to the platform has no relation to year_added.\n",
        "*  **Alternative Hypothesis HA:** The kind of material that is contributed to the platform depends on year_added.\n",
        "\n",
        "\n",
        "**Set significance level to 0.05.**"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Perform Statistical Test to obtain P-Value\n",
        "hypo_data = pd.crosstab(df['type'], df['date_added'], margins=False)\n",
        "hypo_data\n",
        "\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chisquare\n",
        "from scipy.stats import chi2_contingency\n",
        "stat, P, dof, expected = chi2_contingency(hypo_data)\n",
        "# Set the significance level to 0.05\n",
        "alpha = 0.05\n",
        "# Print the results\n",
        "print('p-value:', P)\n",
        "# Check if the calculated p-value is less than the significance level\n",
        "if P < alpha:\n",
        "\n",
        "  # If the p-value is less than the significance level, reject the null hypothesis\n",
        "  print(\"We reject the null hypothesis.\")\n",
        "else:\n",
        "  # If the p-value is greater than or equal to the significance level, fail to reject the null hypothesis\n",
        "  print(\"We fail to reject the null hypothesis.\")\n"
      ],
      "metadata": {
        "id": "cnh1LiAzAVMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will accept the alternative hypothesis and reject the null hypothesis since the p value is less than the significance level."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We looked at the p-value for the hypothesis test using a chi-square contingency analysis."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isna().sum()\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data wrangling stage is when we took care of the missing values."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outliers cannot be detected since the column data types in the dataset are in string format. As a result, we may say that the dataset has no outliers."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no category columns in the dataset since all of the columns are in string format."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "data = df[['title']]\n",
        "data['cluster'] = (df['description'] + ' ' + df['listed_in'] + ' '+ df['cast'] + ' ' + df['country'] + ' ' + df['rating']).astype(str)\n",
        "data.set_index('title', inplace = True)\n",
        "data.head()\n",
        ""
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "def to_lower(x):\n",
        "  return x.lower()\n",
        "\n",
        "# Apply the to_lower() function to the 'tags' column of the DataFrame\n",
        "data['cluster'] = data['cluster'].apply(to_lower)\n",
        "\n",
        "# cross checking our result for the function created\n",
        "print(data['cluster'][0])\n",
        ""
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "# Creating function to remove all the punctuations\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    import string\n",
        "    # Let's replace the punctuations with no space,\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator)\n",
        ""
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data['cluster'] = data['cluster'].apply(remove_punctuation)\n",
        "data.head(10)\n",
        ""
      ],
      "metadata": {
        "id": "mkUkirvNBaUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "# our tags column doesnot have links so removing numbers\n",
        "data['cluster'] = data['cluster'].str.replace(r'\\w*\\d\\w*', '', regex=True)\n",
        "# remove words and digits containing digits\n",
        "\n",
        "# cross checking our result for the function created\n",
        "print(data['cluster'][0])"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces\n",
        "# extracting the stopwords using nltk library\n",
        "st = nltk.corpus.stopwords.words('english')\n",
        "# Let's look at all the stopwords.\n",
        "np.array(st)"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Counts of stopwords: \", len(st))"
      ],
      "metadata": {
        "id": "1LzSOPJhBu6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text\n",
        "def stopwords(text):\n",
        "    '''a function for removing the stopword'''\n",
        "    # deleting the stop words and lowering the case of the chosen words\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in st]\n",
        "    # using a space separator to link the list of words\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cluster'] = data['cluster'].apply(stopwords)\n",
        "data.head(15)\n",
        ""
      ],
      "metadata": {
        "id": "X3jPBYDKB2Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        ""
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making a vectorizer count item\n",
        "count_vectorizer = CountVectorizer()\n",
        "# Using the text data, fit the count vectorizer\n",
        "count_vectorizer.fit(data['cluster'])\n",
        "# collect the vectorizer's vocabulary items\n",
        "dictionary = count_vectorizer.vocabulary_.items()"
      ],
      "metadata": {
        "id": "AuFBkjnwB-HH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary"
      ],
      "metadata": {
        "id": "0JIeTXVzCBP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lists for storing vocabulary and counts\n",
        "vocab = []\n",
        "count = []\n",
        "# loop over each vocab and count attach the result to specified lists\n",
        "for key, value in dictionary:\n",
        "    vocab.append(key)\n",
        "    count.append(value)\n",
        "# Save the count in a panadas dataframe using vocab as the index.\n",
        "vocab_bef_stem = pd.Series(count, index=vocab)\n",
        "# sort the dataframe\n",
        "vocab_before_stem = vocab_bef_stem.sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "UzR_6EYrCVKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_before_stem.head().T"
      ],
      "metadata": {
        "id": "kNr3aIoECYgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_before_stem.tail().T"
      ],
      "metadata": {
        "id": "NyBbzBd9Cb71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def stemming(text):\n",
        "    '''a function which stems each word in the given text'''\n",
        "    text = [stemmer.stem(word) for word in text.split()]\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cluster'] = data['cluster'].apply(stemming)\n",
        "data.head(15)\n",
        ""
      ],
      "metadata": {
        "id": "2NuWPn3BCj8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Snowball Stemmer, often known as the Porter2 stemming method, is an upgraded version of the Porter Stemmer technique that we utilized. It fixes some of the flaws in the Porter Stemmer and performs better when stemming words."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "# making the tfid vectorizer object\n",
        "tfid_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Using text data to fit the vectorizer\n",
        "tfid_vectorizer.fit(data['cluster'])\n",
        "\n",
        "# Gather the vocabulary items used in the vectorizer.\n",
        "dictionary = tfid_vectorizer.vocabulary_.items()"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lists for storing vocabulary and counts\n",
        "vocab = []\n",
        "count = []\n",
        "# loop over each vocab and count attach the result to specified lists\n",
        "for key, value in dictionary:\n",
        "    vocab.append(key)\n",
        "    count.append(value)\n",
        "# store the count in panadas dataframe with vocab as index\n",
        "vocab_after_stem = pd.Series(count, index=vocab)\n",
        "# sort the dataframe\n",
        "vocab_after_stem = vocab_after_stem.sort_values(ascending=False)\n",
        "# plot of the top vocab\n",
        "top_vacab = vocab_after_stem.head(20)\n",
        "top_vacab.plot(kind = 'barh', figsize=(15,10),xlim = (35000, 40300))"
      ],
      "metadata": {
        "id": "_ug00SzWCyol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " We made use of The term frequency-inverse document frequency, or TF-IDF, is a technique for converting text to a numerical vector representation. It brings together two crucial concepts: term frequency (TF) and document frequency (DF)."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "# Appying TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', lowercase=False, max_features=20000)\n",
        "X = vectorizer.fit_transform(data['cluster'])\n",
        ""
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.toarray()[5]"
      ],
      "metadata": {
        "id": "Qpx2tNmqDJkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of the vectorized data\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "CuMS7ZUXDMwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.toarray()"
      ],
      "metadata": {
        "id": "cjDxmwrlDQCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, we believe that dimension reduction is required since it is a statistical approach for lowering the number of random variables in a problem by producing a collection of primary variables."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "h3admtxuDhZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using PCA to reduce dimensionality\n",
        "pca = PCA(random_state=42)\n",
        "pca.fit(X)\n"
      ],
      "metadata": {
        "id": "B9c8cHliNhF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explained variance for different number of components\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.title('PCA - Cumulative explained variance vs Number of components')\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Cumulative explained variance')\n",
        "plt.axhline(y= 0.8, color='red', linestyle='--')\n",
        "plt.axvline(x= 3000, color='green', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MU-_zH6MJrMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reducing the dimensions to 0.95 using pca\n",
        "pca = PCA(n_components=3000, random_state=42)\n",
        "pca.fit(X)\n",
        "\n",
        "# transformed features\n",
        "X = pca.transform(X)\n",
        "\n",
        "# shape of transformed vectors\n",
        "X.shape"
      ],
      "metadata": {
        "id": "RClgLIFkQ8SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The technique of lowering the number of features in a dataset while retaining as much useful information as feasible is known as dimensionality reduction. It is an approach for overcoming the curse of dimensionality, which refers to the problem of rising computing complexity and worse performance of machine learning models as the number of features rises.\n",
        "\n",
        "Dimensionality reduction approaches are classified into two types: feature selection and feature extraction.\n",
        "\n",
        "The process of picking a subset of the most relevant characteristics from the original feature set is known as feature selection. It is a strategy for reducing data dimensionality by deleting unnecessary and superfluous characteristics. The following are examples of common feature selection techniques:\n",
        "\n",
        "Feature selection based on correlation Feature selection based on mutual information Recursive feature removal SelectKBest The technique of extracting additional features from an existing feature set by combining or altering existing features is known as feature extraction. It is a technique that aids in data reduction by generating a new feature space that is more compact and informative than the original feature space. Techniques for extracting features that are often used include:\n",
        "\n",
        "PCA stands for Principal Component Analysis. LDA stands for Linear Discriminant Analysis. Non-Negative Matrix Factorization (NMF) Independent Component Analysis (ICA) Answer Here for Autoencoder."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eblow Method for K-means**"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as sch\n",
        ""
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Elbow method to find optimal clusters\n",
        "wcss = []\n",
        "for i in range(1,26 ):\n",
        "  kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
        "  kmeans.fit(X)\n",
        "  wcss.append(kmeans.inertia_)\n",
        "plt.plot(range(1,26), wcss)\n",
        "plt.title(\"The Elbow Method\")\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RySyPAE2RPWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Silhoutte Score for K-means**"
      ],
      "metadata": {
        "id": "jI4VtmDwRbkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        ""
      ],
      "metadata": {
        "id": "mcCcV0b0Rd5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "range_n_clusters = [i for i in range(2,16)]\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    # Create a subplot with 1 row and 2 columns\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.set_size_inches(18, 7)\n",
        "\n",
        "    # The 1st subplot is the silhouette plot\n",
        "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
        "    # lie within [-0.1, 1]\n",
        "    ax1.set_xlim([-0.1, 1])\n",
        "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
        "    # plots of individual clusters, to demarcate them clearly.\n",
        "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
        "\n",
        "    # Initialize the clusterer with n_clusters value and a random generator\n",
        "    # seed of 10 for reproducibility.\n",
        "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
        "    cluster_labels = clusterer.fit_predict(X)\n",
        "\n",
        "    # The silhouette_score gives the average value for all the samples.\n",
        "    # This gives a perspective into the density and separation of the formed\n",
        "    # clusters\n",
        "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "    print(\"For n_clusters =\", n_clusters,\n",
        "          \"The average silhouette_score is :\", silhouette_avg)\n",
        "\n",
        "    # Compute the silhouette scores for each sample\n",
        "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "\n",
        "    y_lower = 10\n",
        "    for i in range(n_clusters):\n",
        "        # Aggregate the silhouette scores for samples belonging to\n",
        "        # cluster i, and sort them\n",
        "        ith_cluster_silhouette_values = \\\n",
        "            sample_silhouette_values[cluster_labels == i]\n",
        "\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "\n",
        "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                          0, ith_cluster_silhouette_values,\n",
        "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "        # Label the silhouette plots with their cluster numbers at the middle\n",
        "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "        # Compute the new y_lower for next plot\n",
        "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
        "\n",
        "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "    ax1.set_ylabel(\"Cluster label\")\n",
        "\n",
        "    # The vertical line for average silhouette score of all the values\n",
        "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
        "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "    # 2nd Plot showing the actual clusters formed\n",
        "    colors = cm.nipy_spectral(cluster_labels.astype(float) /n_clusters)\n",
        "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
        "                c=colors, edgecolor='k')\n",
        "\n",
        "      # Labeling the clusters\n",
        "    centers = clusterer.cluster_centers_\n",
        "    # Draw white circles at cluster centers\n",
        "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
        "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
        "\n",
        "    for i, c in enumerate(centers):\n",
        "        ax2.scatter(c[0], c[1], alpha=1,\n",
        "                    s=50, edgecolor='k')\n",
        "\n",
        "    ax2.set_title(\"The visualization of the clustered data.\")\n",
        "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
        "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
        "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
        "                  \"with n_clusters = %d\" % n_clusters),\n",
        "                 fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cMfN1uJuRgNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.**"
      ],
      "metadata": {
        "id": "4kyB_bGQR2fH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After reviewing the Silhouette result, we discovered that the best result was attained with 15 clusters, which amounted to 0.010383798598527266."
      ],
      "metadata": {
        "id": "OxAGIU_wR6HA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Explain each evaluation metric's indication towards business and the business impact of the ML model used.**"
      ],
      "metadata": {
        "id": "f3I-VcUWR901"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Silhouette score is used to assess cluster quality in algorithms such as K-Means. It assesses how effectively samples are categorized based on similarity. A high Silhouette score is vital for recommendation systems such as Netflix since it reflects how effective they are at proposing related material. This can lead to profit by providing users with accurate and relevant recommendations."
      ],
      "metadata": {
        "id": "RWvf3XIqSBM7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Dendrogram for K-means**"
      ],
      "metadata": {
        "id": "cCZIOqtVSEod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 15, 10\n",
        "\n",
        "# Here we are Using the dendogram to find the optimal number of clusters\n",
        "import scipy.cluster.hierarchy as sch\n",
        "dendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Description and Listed In')\n",
        "plt.ylabel('Euclidean Distances')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZcckrCQNSHul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.**"
      ],
      "metadata": {
        "id": "AQufZsnMSNre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We examined a specific chart known as a dendrogram to determine the optimal number of groups using a technique known as K-means. We discovered the longest vertical line in this graphic that does not intersect any other horizontal lines. We drew a line through this distance and tallied the number of additional lines it intersected. According to the dendrogram, the ideal number of groups for K-means is 15 clusters."
      ],
      "metadata": {
        "id": "QfqbeHbbSQjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-means Clustering with 18 clusters**"
      ],
      "metadata": {
        "id": "ADyXI3_HSTev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "plt.figure(figsize=(20,6), dpi=120)\n",
        "\n",
        "kmeans= KMeans(n_clusters=18, init= 'k-means++', random_state=9)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Here we are predicting the labels of clusters.\n",
        "label = kmeans.fit_predict(X)\n",
        "# Let's check the unique labels\n",
        "unique_labels = np.unique(label)\n",
        "\n",
        "# function to plot the result\n",
        "for i in unique_labels:\n",
        "    plt.scatter(X[label == i , 0] , X[label == i , 1] , label = i)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "X24VGgZhSWRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-means Clustering with 15 clusters.**"
      ],
      "metadata": {
        "id": "4aFlkpvaSZtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "plt.figure(figsize=(20,6), dpi=120)\n",
        "\n",
        "kmeans= KMeans(n_clusters=15, init= 'k-means++', random_state=9)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Predicting the labels of clusters.\n",
        "label = kmeans.fit_predict(X)\n",
        "# let's check all the unique labels\n",
        "unique_labels = np.unique(label)\n",
        "\n",
        "# function to plot the result\n",
        "for i in unique_labels:\n",
        "    plt.scatter(X[label == i , 0] , X[label == i , 1] , label = i)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k4e_1bRRSc4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hierarchical Clustering:**"
      ],
      "metadata": {
        "id": "J9SmRkQbSfoo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hierarchical Clustering is a sort of unsupervised machine learning clustering technique. Its goal is to arrange comparable data points into clusters based on similarities, resulting in a tree-like structure known as a dendrogram. The method operates by iteratively merging or breaking clusters depending on data point distance.\n",
        "\n",
        "There are two main types of hierarchical clustering:\n",
        "\n",
        "1. Agglomerative Clustering\n",
        "\n",
        "2. Divisive Hierarchical Clustering"
      ],
      "metadata": {
        "id": "99BtdGwMSiMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agglomerative Clustering**"
      ],
      "metadata": {
        "id": "t6eLp05gSm4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing agglomerative clustering\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "hc = AgglomerativeClustering(n_clusters = 15, affinity = 'euclidean', linkage = 'ward')\n",
        "y_hc = hc.fit_predict(X)\n",
        ""
      ],
      "metadata": {
        "id": "PDvidRxTSqEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here visualizing the clusters in three dimensions.\n",
        "plt.figure(figsize=(20,8))\n",
        "plt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], s = 100, label = '1')\n",
        "plt.scatter(X[y_hc == 1, 0], X[y_hc == 1, 1], s = 100, label = '2')\n",
        "plt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 100, label = '3')\n",
        "plt.scatter(X[y_hc == 3, 0], X[y_hc == 3, 1], s = 100, label = '4')\n",
        "plt.scatter(X[y_hc == 4, 0], X[y_hc == 4, 1], s = 100, label = '5')\n",
        "plt.scatter(X[y_hc == 5, 0], X[y_hc == 5, 1], s = 100, label = '6')\n",
        "plt.scatter(X[y_hc == 6, 0], X[y_hc == 6, 1], s = 100, label = '6')\n",
        "plt.scatter(X[y_hc == 7, 0], X[y_hc == 7, 1], s = 100, label = '7')\n",
        "plt.scatter(X[y_hc == 8, 0], X[y_hc == 8, 1], s = 100, label = '8')\n",
        "plt.scatter(X[y_hc == 9, 0], X[y_hc == 9, 1], s = 100, label = '9')\n",
        "plt.scatter(X[y_hc == 10, 0], X[y_hc == 10, 1], s = 100, label = '10')\n",
        "plt.scatter(X[y_hc == 11, 0], X[y_hc == 11, 1], s = 100, label = '11')\n",
        "plt.scatter(X[y_hc == 12, 0], X[y_hc == 12, 1], s = 100, label = '12')\n",
        "plt.scatter(X[y_hc == 13, 0], X[y_hc == 13, 1], s = 100, label = '13')\n",
        "plt.scatter(X[y_hc == 14, 0], X[y_hc == 14, 1], s = 100, label = '14')\n",
        "plt.scatter(X[y_hc == 15, 0], X[y_hc == 15, 1], s = 100, label = '15')\n",
        "plt.title('Clusters of content')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ktOUvBOLStaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used.**"
      ],
      "metadata": {
        "id": "Ra0DfrrfgfJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text-based feature clustering assists Netflix customers in grouping similar content tastes. Well-formed clusters improve the recommendation system by detecting trends and providing customised recommendations. This enhances the platform's user experience and content relevancy."
      ],
      "metadata": {
        "id": "LfnGHbWigiyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Which ML model did you choose from the above created models as your final prediction model and why?**"
      ],
      "metadata": {
        "id": "hDhEU97QglNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-means is a strong data clustering technique that aims to partition a dataset into K separate groups, with each data point belonging to a single cluster. The best number of clusters (15 clusters) was obtained after running K-means, giving optimal grouping for the supplied data."
      ],
      "metadata": {
        "id": "wwDtspyrgof5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RECOMMENDATION**"
      ],
      "metadata": {
        "id": "LN8yinsTgrUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we imported path,Image,WordCloud,STOPWORDS,ImageColorGenerator\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
      ],
      "metadata": {
        "id": "ir9W1DH4gu6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cluster_re'] = kmeans.labels_\n",
        "df.head(5)\n"
      ],
      "metadata": {
        "id": "vdkT2I7sgyDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering the dataframe by cluster number and selected column\n",
        "def func_select_Category(category_name,column_of_choice):\n",
        "  df_word_cloud = df[['cluster_re',column_of_choice]].dropna()\n",
        "  df_word_cloud = df_word_cloud[df_word_cloud['cluster_re']==category_name]\n",
        "  # Concatenating the words in the selected column\n",
        "  text = \" \".join(word for word in df_word_cloud[column_of_choice])\n",
        "   # Setting the stopwords and generate word cloud\n",
        "  stopwords = set(STOPWORDS)\n",
        "  # Generating the word cloud image\n",
        "  wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
        "  # Code to display the word cloud\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.title(f'Cluster: {i}')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "832P0ME8g3O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(15):\n",
        "  func_select_Category(i,'description')\n",
        ""
      ],
      "metadata": {
        "id": "TfVtrktlg6JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for getting the some of the same cluster item details\n",
        "def find_same_cluster_items(name_df):\n",
        "  inp_df = df.loc[df['title'].str.lower() == name_df.lower()]\n",
        "  num = inp_df.cluster_re.iloc[0]\n",
        "  type_df = inp_df.type.iloc[0]\n",
        "  temp_df = df.loc[(df['cluster_re'] == num) & (df['type']==type_df)]\n",
        "  temp_df = temp_df.sample(10)\n",
        "  print(\"The cluster number is {}\".format(num))\n",
        "   #print(\"For n_clusters = {}, silhouette score is {}\".format(n_clusters, score))\n",
        "  return list(temp_df['title'])"
      ],
      "metadata": {
        "id": "eO6NDBplhA1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_same_cluster_items('zodiac')\n",
        ""
      ],
      "metadata": {
        "id": "PmfEM4MIhDpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_same_cluster_items('Thank You')"
      ],
      "metadata": {
        "id": "Smj1ER8bhGl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating the similarity**"
      ],
      "metadata": {
        "id": "XWOWN_jXhJ_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        ""
      ],
      "metadata": {
        "id": "9vc3dA0whL-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute the cosine similarity matrix\n",
        "cosine_sim= linear_kernel(X,X)"
      ],
      "metadata": {
        "id": "Ich-VMRJhPdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Series for getting the index and title\n",
        "indices = pd.Series(df.index,index=df['title']).drop_duplicates()\n",
        "\n"
      ],
      "metadata": {
        "id": "bE2BCzY7hTuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(title, cosine_sim = cosine_sim):\n",
        "\n",
        "    #get index of the matching title\n",
        "    idx=indices[title]\n",
        "\n",
        "    #get the similarity score of the similar titles\n",
        "    sim_scores=list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    #sort the movies based on the similarity score\n",
        "    sim_scores=sorted(sim_scores, key=lambda x:x[1], reverse=True)\n",
        "\n",
        "    #get the similarity score of top 10 movies\n",
        "    sim_scores=sim_scores[1:11]\n",
        "\n",
        "    #get the indices\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    #return the top indices\n",
        "    return df['title'].iloc[movie_indices]\n",
        ""
      ],
      "metadata": {
        "id": "MNIobJ5ChXMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over a set of indices ranging from 0 to 499.\n",
        "# Get the movie title from index i.\n",
        "for i in range(0, 500):\n",
        "  gg = df['title'].iloc[i]\n",
        "  print(gg)\n",
        ""
      ],
      "metadata": {
        "id": "Y2e-uNFYhZ3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating the movie recommendations based on the movie 'Power Rangers Dino Charge '\n",
        "Movies = (get_recommendations('Power Rangers Dino Charge'))\n",
        "Movies\n"
      ],
      "metadata": {
        "id": "hyNp6de-hf4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Generating TV show recommendations based on the TV show 'The Rachel Divide'\n",
        "Tv_shows = (get_recommendations('The Rachel Divide'))\n",
        "Tv_shows"
      ],
      "metadata": {
        "id": "w2bYYyEihix4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion For EDA**"
      ],
      "metadata": {
        "id": "sHRQ3Xrfhx9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. The Netflix movie collection surpasses the TV show offerings, with 30.9% dedicated to TV series and 69.1% to movies. In both cases, TV-MA emerges as the most prevalent rating for television programs, indicating an adult audience preference. This rating garners the highest viewership on Netflix.\n",
        "\n",
        "2. Rather than specifically targeting children, Netflix predominantly focuses on providing content that aligns with the interests of adult and teen audiences. Documentaries rank as the most popular Netflix category, followed by stand-up comedy, dramas, and foreign films. The leading category for Netflix TV programs is kids TV.\n",
        "\n",
        "3. Viewers exhibit a preference for watching new episodes upon initial release, as evidenced by \"Season 1\" being the most common duration for TV shows on Netflix. This pattern may stem from Netflix's robust marketing efforts for new episodes or viewers' heightened interest in shows during their debut.\n",
        "\n",
        "4. The United States contributes a substantial volume of content to Netflix due to its diverse cultural landscape. The availability of content decreases as a country's overall output decreases.\n",
        "\n",
        "5. The data reveals that NC-17 movies tend to have longer runtimes, possibly because they often address mature themes requiring more extensive storytelling. Conversely, movies with a TV-Y classification, suitable for all youngsters, have the shortest average runtime, indicating simpler themes suitable for younger audiences. This information can be valuable for content producers and distributors seeking insights into consumer preferences and trends in the film industry.\n",
        "\n",
        "6. The list of top 15 countries contributing to Netflix demonstrates the United States as the leading contributor, followed by India.\n",
        "\n",
        "7. Notably, the top 10 Netflix directors with the most content are predominantly of foreign origin. Jan Suter stands out as the most prolific filmmaker on Netflix, having produced a substantial amount of content.\n"
      ],
      "metadata": {
        "id": "Mx6gUBMfh2Vr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion** **for Machine Learning Model**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Elbow graph enabled us to identify the number of clusters, ultimately determining it to be 18. This number was discerned by locating a pronounced bend in the curve or a significant deviation from a straight line on the graph. The point on the x-axis corresponding to this juncture was selected as the value indicating the number of clusters.\n",
        "\n",
        "Additionally, we employed the Silhouette score method, and upon evaluating the Silhouette Score, we found that the optimal score, amounting to 0.010383798598527266, was achieved with 15 clusters.\n",
        "\n",
        "To ascertain the ideal number of clusters for K-means from another perspective, we examined the dendrogram. This involved identifying the longest vertical distance that could be drawn without intersecting any other horizontal lines and noting the number of vertical lines crossed after traversing this distance. According to the dendrogram's perspective, 15 clusters emerged as the optimum number for K-means.\n",
        "\n",
        "The clustering of text-based features allows Netflix users to organize similar content preferences. By recognizing patterns and offering personalized recommendations, well-defined clusters enhance the recommendation system, thereby improving the overall user experience and content relevance on the platform."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}